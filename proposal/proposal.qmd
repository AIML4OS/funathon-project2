---
title: "proposal"
---

## Data

Two possibilities:

- Use our open data from the registry.
- Generate synthetic data in English using `llm.lab` ("generate me plausible codes for code XX ") and sample using real label distribution from our data.

Nice task for Mat√©o Morin (intern) who arrives in February and will be working on synthetic data.
The generation process would not be part of the subject but will be disclosed for interested readers.

## Goal

- Task 1: Understand how to train and optimize a `torchTextClassifiers` classifier with overview of different features: custom tokenizer, explainability (a supervised learning approach):
  - Step 1:  from data preprocessing/splitting
  - Step 2: model training and (small) grid search
  - Step 3: log and promote a wrapper on MLFlow
  - Step 4: deploy a model using an API
- Task 2: Understand a simple RAG system (a few-short learning approach)
  - embed a text
  - analyse the retrieval
  - prompt engineering

One notebook for each - independent but that should be done "sequentially".

# Tools

- TTC package for supervised text classification (based on PyTorch and Lightning - deep learning frameworks)
- llm.lab API for RAG, as well as some `qdrant` for vectorial database
- Python